{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6402119",
   "metadata": {},
   "source": [
    "# Tensor Shape Manipulation\n",
    "\n",
    "Notebook on how to use the different reshaping functions for high dimensional tensors. Focuses on:\n",
    "1. `torch.view() / torch.reshape()`\n",
    "2. `torch.permute()`\n",
    "\n",
    "## Example Tensor \n",
    "\n",
    "The examples in this notebook will start with the 4D tensor below with shape 2 x 3 x 2 x 2 (2 RGB 2x2 images).\n",
    "\n",
    "```python\n",
    "[\n",
    "    [\n",
    "        [\n",
    "            [0,1],\n",
    "            [2,3]\n",
    "        ],\n",
    "        [\n",
    "            [4,5],\n",
    "            [6,7]\n",
    "        ],\n",
    "        [\n",
    "            [8,9],\n",
    "            [10,11]\n",
    "        ],\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [12,13],\n",
    "            [14,15]\n",
    "        ],\n",
    "        [\n",
    "            [16,17],\n",
    "            [18,19]\n",
    "        ],\n",
    "        [\n",
    "            [20,21],\n",
    "            [22,23]\n",
    "        ],\n",
    "    ]\n",
    "]\n",
    "```\n",
    "\n",
    "## How is this tensor stored in memory? \n",
    "\n",
    "[Great reference!](https://blog.ezyang.com/2019/05/pytorch-internals/)\n",
    "\n",
    "Under the hood, PyTorch stores tensors as multi-dimensional arrays as contiguous blocks of memory. We also store additional metadata such as the size, device, dtype and **stride**. Stride is used for dense tensors, and is used under the hood for indexing logic. Since all the data is stored as a contiguous block of memory, the stride tells us which physical indices to retrieve data for given an indexing query. \n",
    "\n",
    "For example, if we have a 2x2 tensor and we want to access the bottom left element, we would do `tensor[1,0]`. The stride of this tensor would be `(2,1)`, and we would fetch the (2x1 + 1x0) element using that stride. If we had a 2x3x2x2 tensor, the stride would be `(12,4,2,1)`. To get the very last element, we would do `tensor[1,2,1,1]` and we would access the (12x1 + 4x2 + 2x1 + 1x1) = 23rd element. The stride is the product of all numbers to the right, and we implicitly add a 1 on the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "927917d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b221a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_TENSOR = torch.Tensor([\n",
    "    [\n",
    "        [\n",
    "            [0,1],\n",
    "            [2,3]\n",
    "        ],\n",
    "        [\n",
    "            [4,5],\n",
    "            [6,7]\n",
    "        ],\n",
    "        [\n",
    "            [8,9],\n",
    "            [10,11]\n",
    "        ],\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [12,13],\n",
    "            [14,15]\n",
    "        ],\n",
    "        [\n",
    "            [16,17],\n",
    "            [18,19]\n",
    "        ],\n",
    "        [\n",
    "            [20,21],\n",
    "            [22,23]\n",
    "        ],\n",
    "    ]\n",
    "])\n",
    "# I could have reshaped it, but the whole point is to learn how these work\n",
    "# Check we wrote the tensor correctly\n",
    "assert EXAMPLE_TENSOR.shape == (2,3,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b3af5",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "849cbd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util function for timing the execution time\n",
    "def parent_decorator(num_iterations=10000):\n",
    "    def average_execution_time(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            stats = defaultdict(int)\n",
    "            stats[\"min_time\"] = float(\"inf\")\n",
    "            for i in range(num_iterations):\n",
    "                start_time = time.time()\n",
    "                func(*args, **kwargs)\n",
    "                end_time = time.time()\n",
    "                stats[\"total_time\"] += end_time - start_time\n",
    "                stats[\"num_times\"] += 1\n",
    "                stats[\"max_time\"] = max(end_time - start_time, stats[\"max_time\"])\n",
    "                stats[\"min_time\"] = min(end_time - start_time, stats[\"min_time\"])\n",
    "            stats[\"avg_time\"] = stats[\"total_time\"] / stats[\"num_times\"]\n",
    "            print(stats)\n",
    "        return wrapper\n",
    "    return average_execution_time\n",
    "\n",
    "\n",
    "@parent_decorator()\n",
    "def reshape(t: torch.Tensor, shape: list[int]) -> torch.Tensor:\n",
    "    return t.reshape(shape)\n",
    "\n",
    "@parent_decorator()\n",
    "def view(t: torch.Tensor, shape: list[int]) -> torch.Tensor:\n",
    "    return t.view(shape)\n",
    "\n",
    "@parent_decorator()\n",
    "def permute(t: torch.Tensor, permute_shape: list[int]) -> torch.Tensor:\n",
    "    return t.permute(permute_shape)\n",
    "\n",
    "BENCHMARK_TENSOR = torch.cat([EXAMPLE_TENSOR for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "535e82ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'min_time': 7.152557373046875e-07, 'total_time': 0.020767688751220703, 'num_times': 10000, 'max_time': 0.0032639503479003906, 'avg_time': 2.07676887512207e-06})\n",
      "defaultdict(<class 'int'>, {'min_time': 7.152557373046875e-07, 'total_time': 0.02815866470336914, 'num_times': 10000, 'max_time': 0.0007233619689941406, 'avg_time': 2.8158664703369143e-06})\n",
      "defaultdict(<class 'int'>, {'min_time': 7.152557373046875e-07, 'total_time': 0.01273488998413086, 'num_times': 10000, 'max_time': 2.193450927734375e-05, 'avg_time': 1.273488998413086e-06})\n"
     ]
    }
   ],
   "source": [
    "# The execution times for each method is pretty similar, because all of these return a view\n",
    "# We can't benchmark a tensor that needs to be copied because then view and permute will fail\n",
    "# Given these findings, to raise issues if a copy is required, view should be used\n",
    "# If not having errors is preferred, then reshape is better\n",
    "reshape(BENCHMARK_TENSOR, (20000,2,3,2))\n",
    "view(BENCHMARK_TENSOR, (20000,2,3,2))\n",
    "\n",
    "\n",
    "permute(BENCHMARK_TENSOR, (0,1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28edf30d",
   "metadata": {},
   "source": [
    "### View / Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a32e2f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.],\n",
       "          [ 3.,  4.,  5.]],\n",
       "\n",
       "         [[ 6.,  7.,  8.],\n",
       "          [ 9., 10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[12., 13., 14.],\n",
       "          [15., 16., 17.]],\n",
       "\n",
       "         [[18., 19., 20.],\n",
       "          [21., 22., 23.]]]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_TENSOR.view((2,2,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "338bb98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.],\n",
       "          [ 3.,  4.,  5.]],\n",
       "\n",
       "         [[ 6.,  7.,  8.],\n",
       "          [ 9., 10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[12., 13., 14.],\n",
       "          [15., 16., 17.]],\n",
       "\n",
       "         [[18., 19., 20.],\n",
       "          [21., 22., 23.]]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_TENSOR.reshape((2,2,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2cbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14.],\n",
      "         [15., 16., 17.],\n",
      "         [18., 19., 20.],\n",
      "         [21., 22., 23.]]])\n",
      "tensor([[[[ 0.,  1.,  2.],\n",
      "          [ 3.,  4.,  5.]],\n",
      "\n",
      "         [[ 6.,  7.,  8.],\n",
      "          [ 9., 10., 11.]]],\n",
      "\n",
      "\n",
      "        [[[12., 13., 14.],\n",
      "          [15., 16., 17.]],\n",
      "\n",
      "         [[18., 19., 20.],\n",
      "          [21., 22., 23.]]]])\n",
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]]],\n",
      "\n",
      "\n",
      "        [[[12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]],\n",
       "\n",
       "        [[12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATCH EMBEDDING + MERGING EXAMPLE\n",
    "# Imagine we had a batch of patch embeddings, and turn into a grid of patch embeddings\n",
    "# Here we assume the embedding dimension is 3\n",
    "p_embed = EXAMPLE_TENSOR.view(2, -1, 3)\n",
    "print(p_embed)\n",
    "# Now we want a grid of patches, i.e split the middle dimension into 2\n",
    "# In the patch merge layer, if we had a merge window of 2, we would combine every 4th row in the first printed tensor\n",
    "grid_embed = p_embed.view(2, 2, 2, 3)\n",
    "print(grid_embed)\n",
    "\n",
    "x0 = grid_embed[:, 0::2, 0::2, :]\n",
    "x1 = grid_embed[:, 0::2, 1::2, :]\n",
    "x2 = grid_embed[:, 1::2, 0::2, :]\n",
    "x3 = grid_embed[:, 1::2, 1::2, :]\n",
    "merged = torch.concat([x0, x1, x2, x3], dim=-1)\n",
    "# The merged results should have the first block as a 1-D array in the first tensor, followed by the second one\n",
    "print(merged)\n",
    "# Finally we flatten it so we just have 3 dimensions (i.e B x num_merged_patches x (4x3))\n",
    "# The num of merged patches is 1 for each image\n",
    "merged.view(2, -1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fc8bf94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n",
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n"
     ]
    }
   ],
   "source": [
    "# Flattening is the same as reshaping\n",
    "# It uses reshape under the hood, and is a convenience function\n",
    "# Same with unsqueeze\n",
    "print(EXAMPLE_TENSOR.flatten(start_dim=-2, end_dim=-1))\n",
    "EXAMPLE_TENSOR.flatten(start_dim=-2, end_dim=-1).shape\n",
    "\n",
    "print(EXAMPLE_TENSOR.reshape(2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f2c82ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 1, 2])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_TENSOR.unsqueeze(3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b0b73",
   "metadata": {},
   "source": [
    "### Permute\n",
    "\n",
    "The main difference with Permute is that it changes the order of the underlying elements. Previously, view and reshape altered the shape and stride so that the elements are in order, but just in a different configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea156c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  2.],\n",
       "          [ 1.,  3.]],\n",
       "\n",
       "         [[ 4.,  6.],\n",
       "          [ 5.,  7.]],\n",
       "\n",
       "         [[ 8., 10.],\n",
       "          [ 9., 11.]]],\n",
       "\n",
       "\n",
       "        [[[12., 14.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[16., 18.],\n",
       "          [17., 19.]],\n",
       "\n",
       "         [[20., 22.],\n",
       "          [21., 23.]]]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permute the last two dimensions\n",
    "# Visually, it means that for each 2x2 matrix, we collect the data across columns instead of across rows\n",
    "# For example, [[0,1],[2,3]] -> [[0,2], [1,3]]\n",
    "torch.permute(EXAMPLE_TENSOR, (0,1,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5a860582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3.],\n",
       "        [1., 4.],\n",
       "        [2., 5.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([[0,1,2], [3,4,5]])\n",
    "t.permute((1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9f71e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  6.],\n",
       "         [ 3.,  9.]],\n",
       "\n",
       "        [[ 1.,  7.],\n",
       "         [ 4., 10.]],\n",
       "\n",
       "        [[ 2.,  8.],\n",
       "         [ 5., 11.]]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we reverse the dimension\n",
    "# The columns in the original tensor switch to the batch dimension\n",
    "# The row dimension remains unchanged\n",
    "# The new column dimension is the original batch dimension, so same position in the subsequent element in the batch\n",
    "# The new stride is the original stride but the order changed\n",
    "# A reshape would not change stride order, it would just change the stride to match the reshaped dimensions\n",
    "# Swapping strides is what changes the order\n",
    "t = torch.Tensor([[[0,1,2],[3,4,5]], [[6,7,8],[9,10,11]]])\n",
    "t.permute((2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928efcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permuting and slicing make the tensors not contiguous, as the physical order in memory no longer matches the logical memory\n",
    "t.permute((2,1,0)).is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbebb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-learning-repo-RWqq603u-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
