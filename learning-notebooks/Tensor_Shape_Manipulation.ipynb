{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6402119",
   "metadata": {},
   "source": [
    "# Tensor Shape Manipulation\n",
    "\n",
    "Notebook on how to use the different reshaping functions for high dimensional tensors. Focuses on:\n",
    "1. `torch.view() / torch.reshape()`\n",
    "2. `torch.permute()`\n",
    "\n",
    "## Example Tensor \n",
    "\n",
    "The examples in this notebook will start with the 4D tensor below with shape 2 x 3 x 2 x 2 (2 RGB 2x2 images).\n",
    "\n",
    "```python\n",
    "[\n",
    "    [\n",
    "        [\n",
    "            [0,1],\n",
    "            [2,3]\n",
    "        ],\n",
    "        [\n",
    "            [4,5],\n",
    "            [6,7]\n",
    "        ],\n",
    "        [\n",
    "            [8,9],\n",
    "            [10,11]\n",
    "        ],\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [12,13],\n",
    "            [14,15]\n",
    "        ],\n",
    "        [\n",
    "            [16,17],\n",
    "            [18,19]\n",
    "        ],\n",
    "        [\n",
    "            [20,21],\n",
    "            [22,23]\n",
    "        ],\n",
    "    ]\n",
    "]\n",
    "```\n",
    "\n",
    "## How is this tensor stored in memory? \n",
    "\n",
    "[Great reference!](https://blog.ezyang.com/2019/05/pytorch-internals/)\n",
    "\n",
    "Under the hood, PyTorch stores tensors as multi-dimensional arrays as contiguous blocks of memory. We also store additional metadata such as the size, device, dtype and **stride**. Stride is used for dense tensors, and is used under the hood for indexing logic. Since all the data is stored as a contiguous block of memory, the stride tells us which physical indices to retrieve data for given an indexing query. \n",
    "\n",
    "For example, if we have a 2x2 tensor and we want to access the bottom left element, we would do `tensor[1,0]`. The stride of this tensor would be `(2,1)`, and we would fetch the (2x1 + 1x0) element using that stride. If we had a 2x3x2x2 tensor, the stride would be `(12,4,2,1)`. To get the very last element, we would do `tensor[1,2,1,1]` and we would access the (12x1 + 4x2 + 2x1 + 1x1) = 23rd element. The stride is the product of all numbers to the right, and we implicitly add a 1 on the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "927917d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9b221a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_TENSOR = torch.Tensor([\n",
    "    [\n",
    "        [\n",
    "            [0,1],\n",
    "            [2,3]\n",
    "        ],\n",
    "        [\n",
    "            [4,5],\n",
    "            [6,7]\n",
    "        ],\n",
    "        [\n",
    "            [8,9],\n",
    "            [10,11]\n",
    "        ],\n",
    "    ],\n",
    "    [\n",
    "        [\n",
    "            [12,13],\n",
    "            [14,15]\n",
    "        ],\n",
    "        [\n",
    "            [16,17],\n",
    "            [18,19]\n",
    "        ],\n",
    "        [\n",
    "            [20,21],\n",
    "            [22,23]\n",
    "        ],\n",
    "    ]\n",
    "])\n",
    "# I could have reshaped it, but the whole point is to learn how these work\n",
    "# Check we wrote the tensor correctly\n",
    "assert EXAMPLE_TENSOR.shape == (2,3,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b3af5",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "849cbd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util function for timing the execution time\n",
    "def parent_decorator(num_iterations=10000):\n",
    "    def average_execution_time(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            stats = defaultdict(int)\n",
    "            stats[\"min_time\"] = float(\"inf\")\n",
    "            for i in range(num_iterations):\n",
    "                start_time = time.time()\n",
    "                func(*args, **kwargs)\n",
    "                end_time = time.time()\n",
    "                stats[\"total_time\"] += end_time - start_time\n",
    "                stats[\"num_times\"] += 1\n",
    "                stats[\"max_time\"] = max(end_time - start_time, stats[\"max_time\"])\n",
    "                stats[\"min_time\"] = min(end_time - start_time, stats[\"min_time\"])\n",
    "            stats[\"avg_time\"] = stats[\"total_time\"] / stats[\"num_times\"]\n",
    "            print(stats)\n",
    "        return wrapper\n",
    "    return average_execution_time\n",
    "\n",
    "\n",
    "@parent_decorator()\n",
    "def reshape(t: torch.Tensor, shape: list[int]) -> torch.Tensor:\n",
    "    return t.reshape(shape)\n",
    "\n",
    "@parent_decorator()\n",
    "def view(t: torch.Tensor, shape: list[int]) -> torch.Tensor:\n",
    "    return t.view(shape)\n",
    "\n",
    "@parent_decorator()\n",
    "def permute(t: torch.Tensor, permute_shape: list[int]) -> torch.Tensor:\n",
    "    return t.permute(permute_shape)\n",
    "\n",
    "BENCHMARK_TENSOR = torch.cat([EXAMPLE_TENSOR for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "535e82ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'min_time': 7.152557373046875e-07, 'total_time': 0.013417482376098633, 'num_times': 10000, 'max_time': 0.002130270004272461, 'avg_time': 1.3417482376098633e-06})\n",
      "defaultdict(<class 'int'>, {'min_time': 7.152557373046875e-07, 'total_time': 0.01190328598022461, 'num_times': 10000, 'max_time': 0.0008130073547363281, 'avg_time': 1.190328598022461e-06})\n",
      "defaultdict(<class 'int'>, {'min_time': 7.152557373046875e-07, 'total_time': 0.014023065567016602, 'num_times': 10000, 'max_time': 0.0009658336639404297, 'avg_time': 1.4023065567016602e-06})\n"
     ]
    }
   ],
   "source": [
    "# The execution times for each method is pretty similar, because all of these return a view\n",
    "# We can't benchmark a tensor that needs to be copied because then view and permute will fail\n",
    "# Given these findings, to raise issues if a copy is required, view should be used\n",
    "# If not having errors is preferred, then reshape is better\n",
    "reshape(BENCHMARK_TENSOR, (20000,2,3,2))\n",
    "view(BENCHMARK_TENSOR, (20000,2,3,2))\n",
    "\n",
    "\n",
    "permute(BENCHMARK_TENSOR, (0,1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28edf30d",
   "metadata": {},
   "source": [
    "### View / Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a32e2f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.],\n",
       "          [ 3.,  4.,  5.]],\n",
       "\n",
       "         [[ 6.,  7.,  8.],\n",
       "          [ 9., 10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[12., 13., 14.],\n",
       "          [15., 16., 17.]],\n",
       "\n",
       "         [[18., 19., 20.],\n",
       "          [21., 22., 23.]]]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_TENSOR.view((2,2,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "338bb98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.],\n",
       "          [ 3.,  4.,  5.]],\n",
       "\n",
       "         [[ 6.,  7.,  8.],\n",
       "          [ 9., 10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[12., 13., 14.],\n",
       "          [15., 16., 17.]],\n",
       "\n",
       "         [[18., 19., 20.],\n",
       "          [21., 22., 23.]]]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_TENSOR.reshape((2,2,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2be2cbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14.],\n",
      "         [15., 16., 17.],\n",
      "         [18., 19., 20.],\n",
      "         [21., 22., 23.]]])\n",
      "tensor([[[[ 0.,  1.,  2.],\n",
      "          [ 3.,  4.,  5.]],\n",
      "\n",
      "         [[ 6.,  7.,  8.],\n",
      "          [ 9., 10., 11.]]],\n",
      "\n",
      "\n",
      "        [[[12., 13., 14.],\n",
      "          [15., 16., 17.]],\n",
      "\n",
      "         [[18., 19., 20.],\n",
      "          [21., 22., 23.]]]])\n",
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]]],\n",
      "\n",
      "\n",
      "        [[[12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]],\n",
       "\n",
       "        [[12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.]]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATCH EMBEDDING + MERGING EXAMPLE\n",
    "# Imagine we had a batch of patch embeddings, and turn into a grid of patch embeddings\n",
    "# Here we assume the embedding dimension is 3\n",
    "p_embed = EXAMPLE_TENSOR.view(2, -1, 3)\n",
    "print(p_embed)\n",
    "# Now we want a grid of patches, i.e split the middle dimension into 2\n",
    "# In the patch merge layer, if we had a merge window of 2, we would combine every 4th row in the first printed tensor\n",
    "grid_embed = p_embed.view(2, 2, 2, 3)\n",
    "print(grid_embed)\n",
    "\n",
    "x0 = grid_embed[:, 0::2, 0::2, :]\n",
    "x1 = grid_embed[:, 0::2, 1::2, :]\n",
    "x2 = grid_embed[:, 1::2, 0::2, :]\n",
    "x3 = grid_embed[:, 1::2, 1::2, :]\n",
    "merged = torch.concat([x0, x1, x2, x3], dim=-1)\n",
    "# The merged results should have the first block as a 1-D array in the first tensor, followed by the second one\n",
    "print(merged)\n",
    "# Finally we flatten it so we just have 3 dimensions (i.e B x num_merged_patches x (4x3))\n",
    "# The num of merged patches is 1 for each image\n",
    "merged.view(2, -1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fc8bf94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n",
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n"
     ]
    }
   ],
   "source": [
    "# Flattening is the same as reshaping\n",
    "# It uses reshape under the hood, and is a convenience function\n",
    "# Same with unsqueeze\n",
    "print(EXAMPLE_TENSOR.flatten(start_dim=-2, end_dim=-1))\n",
    "EXAMPLE_TENSOR.flatten(start_dim=-2, end_dim=-1).shape\n",
    "\n",
    "print(EXAMPLE_TENSOR.reshape(2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f2c82ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 1, 2])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_TENSOR.unsqueeze(3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b0b73",
   "metadata": {},
   "source": [
    "### Permute\n",
    "\n",
    "The main difference with Permute is that it changes the order of the underlying elements. Previously, view and reshape altered the shape and stride so that the elements are in order, but just in a different configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ea156c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  2.],\n",
       "          [ 1.,  3.]],\n",
       "\n",
       "         [[ 4.,  6.],\n",
       "          [ 5.,  7.]],\n",
       "\n",
       "         [[ 8., 10.],\n",
       "          [ 9., 11.]]],\n",
       "\n",
       "\n",
       "        [[[12., 14.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[16., 18.],\n",
       "          [17., 19.]],\n",
       "\n",
       "         [[20., 22.],\n",
       "          [21., 23.]]]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permute the last two dimensions\n",
    "# Visually, it means that for each 2x2 matrix, we collect the data across columns instead of across rows\n",
    "# For example, [[0,1],[2,3]] -> [[0,2], [1,3]]\n",
    "torch.permute(EXAMPLE_TENSOR, (0,1,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5a860582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3.],\n",
       "        [1., 4.],\n",
       "        [2., 5.]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([[0,1,2], [3,4,5]])\n",
    "t.permute((1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9f71e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  6.],\n",
       "         [ 3.,  9.]],\n",
       "\n",
       "        [[ 1.,  7.],\n",
       "         [ 4., 10.]],\n",
       "\n",
       "        [[ 2.,  8.],\n",
       "         [ 5., 11.]]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we reverse the dimension\n",
    "# The columns in the original tensor switch to the batch dimension\n",
    "# The row dimension remains unchanged\n",
    "# The new column dimension is the original batch dimension, so same position in the subsequent element in the batch\n",
    "# The new stride is the original stride but the order changed\n",
    "# A reshape would not change stride order, it would just change the stride to match the reshaped dimensions\n",
    "# Swapping strides is what changes the order\n",
    "t = torch.Tensor([[[0,1,2],[3,4,5]], [[6,7,8],[9,10,11]]])\n",
    "t.permute((2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "928efcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permuting and slicing make the tensors not contiguous, as the physical order in memory no longer matches the logical memory\n",
    "t.permute((2,1,0)).is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbebb86",
   "metadata": {},
   "source": [
    "### Window Splitter Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "50874e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0,   1,   2],\n",
       "          [  3,   4,   5],\n",
       "          [  6,   7,   8],\n",
       "          [  9,  10,  11],\n",
       "          [ 12,  13,  14],\n",
       "          [ 15,  16,  17]],\n",
       "\n",
       "         [[ 18,  19,  20],\n",
       "          [ 21,  22,  23],\n",
       "          [ 24,  25,  26],\n",
       "          [ 27,  28,  29],\n",
       "          [ 30,  31,  32],\n",
       "          [ 33,  34,  35]],\n",
       "\n",
       "         [[ 36,  37,  38],\n",
       "          [ 39,  40,  41],\n",
       "          [ 42,  43,  44],\n",
       "          [ 45,  46,  47],\n",
       "          [ 48,  49,  50],\n",
       "          [ 51,  52,  53]],\n",
       "\n",
       "         [[ 54,  55,  56],\n",
       "          [ 57,  58,  59],\n",
       "          [ 60,  61,  62],\n",
       "          [ 63,  64,  65],\n",
       "          [ 66,  67,  68],\n",
       "          [ 69,  70,  71]],\n",
       "\n",
       "         [[ 72,  73,  74],\n",
       "          [ 75,  76,  77],\n",
       "          [ 78,  79,  80],\n",
       "          [ 81,  82,  83],\n",
       "          [ 84,  85,  86],\n",
       "          [ 87,  88,  89]],\n",
       "\n",
       "         [[ 90,  91,  92],\n",
       "          [ 93,  94,  95],\n",
       "          [ 96,  97,  98],\n",
       "          [ 99, 100, 101],\n",
       "          [102, 103, 104],\n",
       "          [105, 106, 107]]],\n",
       "\n",
       "\n",
       "        [[[108, 109, 110],\n",
       "          [111, 112, 113],\n",
       "          [114, 115, 116],\n",
       "          [117, 118, 119],\n",
       "          [120, 121, 122],\n",
       "          [123, 124, 125]],\n",
       "\n",
       "         [[126, 127, 128],\n",
       "          [129, 130, 131],\n",
       "          [132, 133, 134],\n",
       "          [135, 136, 137],\n",
       "          [138, 139, 140],\n",
       "          [141, 142, 143]],\n",
       "\n",
       "         [[144, 145, 146],\n",
       "          [147, 148, 149],\n",
       "          [150, 151, 152],\n",
       "          [153, 154, 155],\n",
       "          [156, 157, 158],\n",
       "          [159, 160, 161]],\n",
       "\n",
       "         [[162, 163, 164],\n",
       "          [165, 166, 167],\n",
       "          [168, 169, 170],\n",
       "          [171, 172, 173],\n",
       "          [174, 175, 176],\n",
       "          [177, 178, 179]],\n",
       "\n",
       "         [[180, 181, 182],\n",
       "          [183, 184, 185],\n",
       "          [186, 187, 188],\n",
       "          [189, 190, 191],\n",
       "          [192, 193, 194],\n",
       "          [195, 196, 197]],\n",
       "\n",
       "         [[198, 199, 200],\n",
       "          [201, 202, 203],\n",
       "          [204, 205, 206],\n",
       "          [207, 208, 209],\n",
       "          [210, 211, 212],\n",
       "          [213, 214, 215]]]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imagine we have a grid of (merged) patch embeddings\n",
    "# Has shape B x H x W x C\n",
    "# We will split H and W by M in each dimension, so H and W need to be slightly bigger\n",
    "# Create a 2 x 6 x 6 x 3 tensor\n",
    "t = torch.arange(2*6*6*3).view((2,6,6,3))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "98d4c467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0,   1,   2],\n",
       "          [  3,   4,   5]],\n",
       "\n",
       "         [[ 18,  19,  20],\n",
       "          [ 21,  22,  23]]],\n",
       "\n",
       "\n",
       "        [[[  6,   7,   8],\n",
       "          [  9,  10,  11]],\n",
       "\n",
       "         [[ 24,  25,  26],\n",
       "          [ 27,  28,  29]]],\n",
       "\n",
       "\n",
       "        [[[ 12,  13,  14],\n",
       "          [ 15,  16,  17]],\n",
       "\n",
       "         [[ 30,  31,  32],\n",
       "          [ 33,  34,  35]]],\n",
       "\n",
       "\n",
       "        [[[ 36,  37,  38],\n",
       "          [ 39,  40,  41]],\n",
       "\n",
       "         [[ 54,  55,  56],\n",
       "          [ 57,  58,  59]]],\n",
       "\n",
       "\n",
       "        [[[ 42,  43,  44],\n",
       "          [ 45,  46,  47]],\n",
       "\n",
       "         [[ 60,  61,  62],\n",
       "          [ 63,  64,  65]]],\n",
       "\n",
       "\n",
       "        [[[ 48,  49,  50],\n",
       "          [ 51,  52,  53]],\n",
       "\n",
       "         [[ 66,  67,  68],\n",
       "          [ 69,  70,  71]]],\n",
       "\n",
       "\n",
       "        [[[ 72,  73,  74],\n",
       "          [ 75,  76,  77]],\n",
       "\n",
       "         [[ 90,  91,  92],\n",
       "          [ 93,  94,  95]]],\n",
       "\n",
       "\n",
       "        [[[ 78,  79,  80],\n",
       "          [ 81,  82,  83]],\n",
       "\n",
       "         [[ 96,  97,  98],\n",
       "          [ 99, 100, 101]]],\n",
       "\n",
       "\n",
       "        [[[ 84,  85,  86],\n",
       "          [ 87,  88,  89]],\n",
       "\n",
       "         [[102, 103, 104],\n",
       "          [105, 106, 107]]],\n",
       "\n",
       "\n",
       "        [[[108, 109, 110],\n",
       "          [111, 112, 113]],\n",
       "\n",
       "         [[126, 127, 128],\n",
       "          [129, 130, 131]]],\n",
       "\n",
       "\n",
       "        [[[114, 115, 116],\n",
       "          [117, 118, 119]],\n",
       "\n",
       "         [[132, 133, 134],\n",
       "          [135, 136, 137]]],\n",
       "\n",
       "\n",
       "        [[[120, 121, 122],\n",
       "          [123, 124, 125]],\n",
       "\n",
       "         [[138, 139, 140],\n",
       "          [141, 142, 143]]],\n",
       "\n",
       "\n",
       "        [[[144, 145, 146],\n",
       "          [147, 148, 149]],\n",
       "\n",
       "         [[162, 163, 164],\n",
       "          [165, 166, 167]]],\n",
       "\n",
       "\n",
       "        [[[150, 151, 152],\n",
       "          [153, 154, 155]],\n",
       "\n",
       "         [[168, 169, 170],\n",
       "          [171, 172, 173]]],\n",
       "\n",
       "\n",
       "        [[[156, 157, 158],\n",
       "          [159, 160, 161]],\n",
       "\n",
       "         [[174, 175, 176],\n",
       "          [177, 178, 179]]],\n",
       "\n",
       "\n",
       "        [[[180, 181, 182],\n",
       "          [183, 184, 185]],\n",
       "\n",
       "         [[198, 199, 200],\n",
       "          [201, 202, 203]]],\n",
       "\n",
       "\n",
       "        [[[186, 187, 188],\n",
       "          [189, 190, 191]],\n",
       "\n",
       "         [[204, 205, 206],\n",
       "          [207, 208, 209]]],\n",
       "\n",
       "\n",
       "        [[[192, 193, 194],\n",
       "          [195, 196, 197]],\n",
       "\n",
       "         [[210, 211, 212],\n",
       "          [213, 214, 215]]]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we permute so and reduce the shape so we have the number of patches absorbed into the batch dimension\n",
    "windowed = t.view((2,3,2,3,2,3))\n",
    "windowed.permute((0,1,3,2,4,5)).reshape(-1, 2,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4806513d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  0,   1,   2],\n",
       "          [  3,   4,   5]],\n",
       "\n",
       "         [[  6,   7,   8],\n",
       "          [  9,  10,  11]]],\n",
       "\n",
       "\n",
       "        [[[ 12,  13,  14],\n",
       "          [ 15,  16,  17]],\n",
       "\n",
       "         [[ 18,  19,  20],\n",
       "          [ 21,  22,  23]]],\n",
       "\n",
       "\n",
       "        [[[ 24,  25,  26],\n",
       "          [ 27,  28,  29]],\n",
       "\n",
       "         [[ 30,  31,  32],\n",
       "          [ 33,  34,  35]]],\n",
       "\n",
       "\n",
       "        [[[ 36,  37,  38],\n",
       "          [ 39,  40,  41]],\n",
       "\n",
       "         [[ 42,  43,  44],\n",
       "          [ 45,  46,  47]]],\n",
       "\n",
       "\n",
       "        [[[ 48,  49,  50],\n",
       "          [ 51,  52,  53]],\n",
       "\n",
       "         [[ 54,  55,  56],\n",
       "          [ 57,  58,  59]]],\n",
       "\n",
       "\n",
       "        [[[ 60,  61,  62],\n",
       "          [ 63,  64,  65]],\n",
       "\n",
       "         [[ 66,  67,  68],\n",
       "          [ 69,  70,  71]]],\n",
       "\n",
       "\n",
       "        [[[ 72,  73,  74],\n",
       "          [ 75,  76,  77]],\n",
       "\n",
       "         [[ 78,  79,  80],\n",
       "          [ 81,  82,  83]]],\n",
       "\n",
       "\n",
       "        [[[ 84,  85,  86],\n",
       "          [ 87,  88,  89]],\n",
       "\n",
       "         [[ 90,  91,  92],\n",
       "          [ 93,  94,  95]]],\n",
       "\n",
       "\n",
       "        [[[ 96,  97,  98],\n",
       "          [ 99, 100, 101]],\n",
       "\n",
       "         [[102, 103, 104],\n",
       "          [105, 106, 107]]],\n",
       "\n",
       "\n",
       "        [[[108, 109, 110],\n",
       "          [111, 112, 113]],\n",
       "\n",
       "         [[114, 115, 116],\n",
       "          [117, 118, 119]]],\n",
       "\n",
       "\n",
       "        [[[120, 121, 122],\n",
       "          [123, 124, 125]],\n",
       "\n",
       "         [[126, 127, 128],\n",
       "          [129, 130, 131]]],\n",
       "\n",
       "\n",
       "        [[[132, 133, 134],\n",
       "          [135, 136, 137]],\n",
       "\n",
       "         [[138, 139, 140],\n",
       "          [141, 142, 143]]],\n",
       "\n",
       "\n",
       "        [[[144, 145, 146],\n",
       "          [147, 148, 149]],\n",
       "\n",
       "         [[150, 151, 152],\n",
       "          [153, 154, 155]]],\n",
       "\n",
       "\n",
       "        [[[156, 157, 158],\n",
       "          [159, 160, 161]],\n",
       "\n",
       "         [[162, 163, 164],\n",
       "          [165, 166, 167]]],\n",
       "\n",
       "\n",
       "        [[[168, 169, 170],\n",
       "          [171, 172, 173]],\n",
       "\n",
       "         [[174, 175, 176],\n",
       "          [177, 178, 179]]],\n",
       "\n",
       "\n",
       "        [[[180, 181, 182],\n",
       "          [183, 184, 185]],\n",
       "\n",
       "         [[186, 187, 188],\n",
       "          [189, 190, 191]]],\n",
       "\n",
       "\n",
       "        [[[192, 193, 194],\n",
       "          [195, 196, 197]],\n",
       "\n",
       "         [[198, 199, 200],\n",
       "          [201, 202, 203]]],\n",
       "\n",
       "\n",
       "        [[[204, 205, 206],\n",
       "          [207, 208, 209]],\n",
       "\n",
       "         [[210, 211, 212],\n",
       "          [213, 214, 215]]]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What if we moved the windows to the outer dims and then permuted\n",
    "windowed_2 = t.view((2,3,3,2,2,3))\n",
    "windowed_2.permute((0,1,2,3,4,5)).reshape(-1, 2,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad26f69",
   "metadata": {},
   "source": [
    "### Window Self Attention Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f4316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11],\n",
       "         [ 12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23],\n",
       "         [ 24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35],\n",
       "         [ 36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47]],\n",
       "\n",
       "        [[ 48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59],\n",
       "         [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71],\n",
       "         [ 72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83],\n",
       "         [ 84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95]],\n",
       "\n",
       "        [[ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107],\n",
       "         [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119],\n",
       "         [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131],\n",
       "         [132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]],\n",
       "\n",
       "        [[144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155],\n",
       "         [156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167],\n",
       "         [168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179],\n",
       "         [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]],\n",
       "\n",
       "        [[192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203],\n",
       "         [204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215],\n",
       "         [216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227],\n",
       "         [228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]],\n",
       "\n",
       "        [[240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251],\n",
       "         [252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263],\n",
       "         [264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275],\n",
       "         [276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287]],\n",
       "\n",
       "        [[288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299],\n",
       "         [300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311],\n",
       "         [312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323],\n",
       "         [324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335]],\n",
       "\n",
       "        [[336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347],\n",
       "         [348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359],\n",
       "         [360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371],\n",
       "         [372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383]]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imagine we have a (B x H/M x W/M) x M^2 x C tensor to run windowed self-attention on\n",
    "# We need to split the projected tensor into 3 separate tensors, and have a head dimension.\n",
    "# We want to end up with a 3 x (B x H/M x W/M) x HEADS x M^2 x C tensor\n",
    "# What is the difference if we reshape it directly versus permuting?\n",
    "\n",
    "t = torch.arange(8 * 4 * 12).reshape(8, 4, 12)\n",
    "t\n",
    "# The initial tensor has 12 dimensions per embedding, with a head dim of 2, 2 heads and Q,K,V respectively.\n",
    "# Imagine that for the first patch, 0-3 are Q, 4-7 are K and 8-11 are V\n",
    "# The first head would use 0-1 as Q, 4-5 as K and 8-9 as V\n",
    "# Therefore to pay attention to the right things, we would want: \n",
    "# Q's first head as [0,1],[12,13],[24,25],[36,37]. This is the first element in the overall tensor.\n",
    "# We can't keep the order, otherwise the Q tensor contains information from the same patch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8160c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[  0,   1],\n",
       "           [  2,   3],\n",
       "           [  4,   5],\n",
       "           [  6,   7]],\n",
       "\n",
       "          [[  8,   9],\n",
       "           [ 10,  11],\n",
       "           [ 12,  13],\n",
       "           [ 14,  15]]],\n",
       "\n",
       "\n",
       "         [[[ 16,  17],\n",
       "           [ 18,  19],\n",
       "           [ 20,  21],\n",
       "           [ 22,  23]],\n",
       "\n",
       "          [[ 24,  25],\n",
       "           [ 26,  27],\n",
       "           [ 28,  29],\n",
       "           [ 30,  31]]],\n",
       "\n",
       "\n",
       "         [[[ 32,  33],\n",
       "           [ 34,  35],\n",
       "           [ 36,  37],\n",
       "           [ 38,  39]],\n",
       "\n",
       "          [[ 40,  41],\n",
       "           [ 42,  43],\n",
       "           [ 44,  45],\n",
       "           [ 46,  47]]],\n",
       "\n",
       "\n",
       "         [[[ 48,  49],\n",
       "           [ 50,  51],\n",
       "           [ 52,  53],\n",
       "           [ 54,  55]],\n",
       "\n",
       "          [[ 56,  57],\n",
       "           [ 58,  59],\n",
       "           [ 60,  61],\n",
       "           [ 62,  63]]],\n",
       "\n",
       "\n",
       "         [[[ 64,  65],\n",
       "           [ 66,  67],\n",
       "           [ 68,  69],\n",
       "           [ 70,  71]],\n",
       "\n",
       "          [[ 72,  73],\n",
       "           [ 74,  75],\n",
       "           [ 76,  77],\n",
       "           [ 78,  79]]],\n",
       "\n",
       "\n",
       "         [[[ 80,  81],\n",
       "           [ 82,  83],\n",
       "           [ 84,  85],\n",
       "           [ 86,  87]],\n",
       "\n",
       "          [[ 88,  89],\n",
       "           [ 90,  91],\n",
       "           [ 92,  93],\n",
       "           [ 94,  95]]],\n",
       "\n",
       "\n",
       "         [[[ 96,  97],\n",
       "           [ 98,  99],\n",
       "           [100, 101],\n",
       "           [102, 103]],\n",
       "\n",
       "          [[104, 105],\n",
       "           [106, 107],\n",
       "           [108, 109],\n",
       "           [110, 111]]],\n",
       "\n",
       "\n",
       "         [[[112, 113],\n",
       "           [114, 115],\n",
       "           [116, 117],\n",
       "           [118, 119]],\n",
       "\n",
       "          [[120, 121],\n",
       "           [122, 123],\n",
       "           [124, 125],\n",
       "           [126, 127]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[128, 129],\n",
       "           [130, 131],\n",
       "           [132, 133],\n",
       "           [134, 135]],\n",
       "\n",
       "          [[136, 137],\n",
       "           [138, 139],\n",
       "           [140, 141],\n",
       "           [142, 143]]],\n",
       "\n",
       "\n",
       "         [[[144, 145],\n",
       "           [146, 147],\n",
       "           [148, 149],\n",
       "           [150, 151]],\n",
       "\n",
       "          [[152, 153],\n",
       "           [154, 155],\n",
       "           [156, 157],\n",
       "           [158, 159]]],\n",
       "\n",
       "\n",
       "         [[[160, 161],\n",
       "           [162, 163],\n",
       "           [164, 165],\n",
       "           [166, 167]],\n",
       "\n",
       "          [[168, 169],\n",
       "           [170, 171],\n",
       "           [172, 173],\n",
       "           [174, 175]]],\n",
       "\n",
       "\n",
       "         [[[176, 177],\n",
       "           [178, 179],\n",
       "           [180, 181],\n",
       "           [182, 183]],\n",
       "\n",
       "          [[184, 185],\n",
       "           [186, 187],\n",
       "           [188, 189],\n",
       "           [190, 191]]],\n",
       "\n",
       "\n",
       "         [[[192, 193],\n",
       "           [194, 195],\n",
       "           [196, 197],\n",
       "           [198, 199]],\n",
       "\n",
       "          [[200, 201],\n",
       "           [202, 203],\n",
       "           [204, 205],\n",
       "           [206, 207]]],\n",
       "\n",
       "\n",
       "         [[[208, 209],\n",
       "           [210, 211],\n",
       "           [212, 213],\n",
       "           [214, 215]],\n",
       "\n",
       "          [[216, 217],\n",
       "           [218, 219],\n",
       "           [220, 221],\n",
       "           [222, 223]]],\n",
       "\n",
       "\n",
       "         [[[224, 225],\n",
       "           [226, 227],\n",
       "           [228, 229],\n",
       "           [230, 231]],\n",
       "\n",
       "          [[232, 233],\n",
       "           [234, 235],\n",
       "           [236, 237],\n",
       "           [238, 239]]],\n",
       "\n",
       "\n",
       "         [[[240, 241],\n",
       "           [242, 243],\n",
       "           [244, 245],\n",
       "           [246, 247]],\n",
       "\n",
       "          [[248, 249],\n",
       "           [250, 251],\n",
       "           [252, 253],\n",
       "           [254, 255]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[256, 257],\n",
       "           [258, 259],\n",
       "           [260, 261],\n",
       "           [262, 263]],\n",
       "\n",
       "          [[264, 265],\n",
       "           [266, 267],\n",
       "           [268, 269],\n",
       "           [270, 271]]],\n",
       "\n",
       "\n",
       "         [[[272, 273],\n",
       "           [274, 275],\n",
       "           [276, 277],\n",
       "           [278, 279]],\n",
       "\n",
       "          [[280, 281],\n",
       "           [282, 283],\n",
       "           [284, 285],\n",
       "           [286, 287]]],\n",
       "\n",
       "\n",
       "         [[[288, 289],\n",
       "           [290, 291],\n",
       "           [292, 293],\n",
       "           [294, 295]],\n",
       "\n",
       "          [[296, 297],\n",
       "           [298, 299],\n",
       "           [300, 301],\n",
       "           [302, 303]]],\n",
       "\n",
       "\n",
       "         [[[304, 305],\n",
       "           [306, 307],\n",
       "           [308, 309],\n",
       "           [310, 311]],\n",
       "\n",
       "          [[312, 313],\n",
       "           [314, 315],\n",
       "           [316, 317],\n",
       "           [318, 319]]],\n",
       "\n",
       "\n",
       "         [[[320, 321],\n",
       "           [322, 323],\n",
       "           [324, 325],\n",
       "           [326, 327]],\n",
       "\n",
       "          [[328, 329],\n",
       "           [330, 331],\n",
       "           [332, 333],\n",
       "           [334, 335]]],\n",
       "\n",
       "\n",
       "         [[[336, 337],\n",
       "           [338, 339],\n",
       "           [340, 341],\n",
       "           [342, 343]],\n",
       "\n",
       "          [[344, 345],\n",
       "           [346, 347],\n",
       "           [348, 349],\n",
       "           [350, 351]]],\n",
       "\n",
       "\n",
       "         [[[352, 353],\n",
       "           [354, 355],\n",
       "           [356, 357],\n",
       "           [358, 359]],\n",
       "\n",
       "          [[360, 361],\n",
       "           [362, 363],\n",
       "           [364, 365],\n",
       "           [366, 367]]],\n",
       "\n",
       "\n",
       "         [[[368, 369],\n",
       "           [370, 371],\n",
       "           [372, 373],\n",
       "           [374, 375]],\n",
       "\n",
       "          [[376, 377],\n",
       "           [378, 379],\n",
       "           [380, 381],\n",
       "           [382, 383]]]]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A view of the output shape we want is incorrect, because Q for the first head now only contains info from the first patch\n",
    "# But actually it should have certain dimensions from the first 4 patches\n",
    "t.view(3,8,2,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ced11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[  0,   1],\n",
       "           [ 12,  13],\n",
       "           [ 24,  25],\n",
       "           [ 36,  37]],\n",
       "\n",
       "          [[  2,   3],\n",
       "           [ 14,  15],\n",
       "           [ 26,  27],\n",
       "           [ 38,  39]]],\n",
       "\n",
       "\n",
       "         [[[ 48,  49],\n",
       "           [ 60,  61],\n",
       "           [ 72,  73],\n",
       "           [ 84,  85]],\n",
       "\n",
       "          [[ 50,  51],\n",
       "           [ 62,  63],\n",
       "           [ 74,  75],\n",
       "           [ 86,  87]]],\n",
       "\n",
       "\n",
       "         [[[ 96,  97],\n",
       "           [108, 109],\n",
       "           [120, 121],\n",
       "           [132, 133]],\n",
       "\n",
       "          [[ 98,  99],\n",
       "           [110, 111],\n",
       "           [122, 123],\n",
       "           [134, 135]]],\n",
       "\n",
       "\n",
       "         [[[144, 145],\n",
       "           [156, 157],\n",
       "           [168, 169],\n",
       "           [180, 181]],\n",
       "\n",
       "          [[146, 147],\n",
       "           [158, 159],\n",
       "           [170, 171],\n",
       "           [182, 183]]],\n",
       "\n",
       "\n",
       "         [[[192, 193],\n",
       "           [204, 205],\n",
       "           [216, 217],\n",
       "           [228, 229]],\n",
       "\n",
       "          [[194, 195],\n",
       "           [206, 207],\n",
       "           [218, 219],\n",
       "           [230, 231]]],\n",
       "\n",
       "\n",
       "         [[[240, 241],\n",
       "           [252, 253],\n",
       "           [264, 265],\n",
       "           [276, 277]],\n",
       "\n",
       "          [[242, 243],\n",
       "           [254, 255],\n",
       "           [266, 267],\n",
       "           [278, 279]]],\n",
       "\n",
       "\n",
       "         [[[288, 289],\n",
       "           [300, 301],\n",
       "           [312, 313],\n",
       "           [324, 325]],\n",
       "\n",
       "          [[290, 291],\n",
       "           [302, 303],\n",
       "           [314, 315],\n",
       "           [326, 327]]],\n",
       "\n",
       "\n",
       "         [[[336, 337],\n",
       "           [348, 349],\n",
       "           [360, 361],\n",
       "           [372, 373]],\n",
       "\n",
       "          [[338, 339],\n",
       "           [350, 351],\n",
       "           [362, 363],\n",
       "           [374, 375]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[  4,   5],\n",
       "           [ 16,  17],\n",
       "           [ 28,  29],\n",
       "           [ 40,  41]],\n",
       "\n",
       "          [[  6,   7],\n",
       "           [ 18,  19],\n",
       "           [ 30,  31],\n",
       "           [ 42,  43]]],\n",
       "\n",
       "\n",
       "         [[[ 52,  53],\n",
       "           [ 64,  65],\n",
       "           [ 76,  77],\n",
       "           [ 88,  89]],\n",
       "\n",
       "          [[ 54,  55],\n",
       "           [ 66,  67],\n",
       "           [ 78,  79],\n",
       "           [ 90,  91]]],\n",
       "\n",
       "\n",
       "         [[[100, 101],\n",
       "           [112, 113],\n",
       "           [124, 125],\n",
       "           [136, 137]],\n",
       "\n",
       "          [[102, 103],\n",
       "           [114, 115],\n",
       "           [126, 127],\n",
       "           [138, 139]]],\n",
       "\n",
       "\n",
       "         [[[148, 149],\n",
       "           [160, 161],\n",
       "           [172, 173],\n",
       "           [184, 185]],\n",
       "\n",
       "          [[150, 151],\n",
       "           [162, 163],\n",
       "           [174, 175],\n",
       "           [186, 187]]],\n",
       "\n",
       "\n",
       "         [[[196, 197],\n",
       "           [208, 209],\n",
       "           [220, 221],\n",
       "           [232, 233]],\n",
       "\n",
       "          [[198, 199],\n",
       "           [210, 211],\n",
       "           [222, 223],\n",
       "           [234, 235]]],\n",
       "\n",
       "\n",
       "         [[[244, 245],\n",
       "           [256, 257],\n",
       "           [268, 269],\n",
       "           [280, 281]],\n",
       "\n",
       "          [[246, 247],\n",
       "           [258, 259],\n",
       "           [270, 271],\n",
       "           [282, 283]]],\n",
       "\n",
       "\n",
       "         [[[292, 293],\n",
       "           [304, 305],\n",
       "           [316, 317],\n",
       "           [328, 329]],\n",
       "\n",
       "          [[294, 295],\n",
       "           [306, 307],\n",
       "           [318, 319],\n",
       "           [330, 331]]],\n",
       "\n",
       "\n",
       "         [[[340, 341],\n",
       "           [352, 353],\n",
       "           [364, 365],\n",
       "           [376, 377]],\n",
       "\n",
       "          [[342, 343],\n",
       "           [354, 355],\n",
       "           [366, 367],\n",
       "           [378, 379]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[  8,   9],\n",
       "           [ 20,  21],\n",
       "           [ 32,  33],\n",
       "           [ 44,  45]],\n",
       "\n",
       "          [[ 10,  11],\n",
       "           [ 22,  23],\n",
       "           [ 34,  35],\n",
       "           [ 46,  47]]],\n",
       "\n",
       "\n",
       "         [[[ 56,  57],\n",
       "           [ 68,  69],\n",
       "           [ 80,  81],\n",
       "           [ 92,  93]],\n",
       "\n",
       "          [[ 58,  59],\n",
       "           [ 70,  71],\n",
       "           [ 82,  83],\n",
       "           [ 94,  95]]],\n",
       "\n",
       "\n",
       "         [[[104, 105],\n",
       "           [116, 117],\n",
       "           [128, 129],\n",
       "           [140, 141]],\n",
       "\n",
       "          [[106, 107],\n",
       "           [118, 119],\n",
       "           [130, 131],\n",
       "           [142, 143]]],\n",
       "\n",
       "\n",
       "         [[[152, 153],\n",
       "           [164, 165],\n",
       "           [176, 177],\n",
       "           [188, 189]],\n",
       "\n",
       "          [[154, 155],\n",
       "           [166, 167],\n",
       "           [178, 179],\n",
       "           [190, 191]]],\n",
       "\n",
       "\n",
       "         [[[200, 201],\n",
       "           [212, 213],\n",
       "           [224, 225],\n",
       "           [236, 237]],\n",
       "\n",
       "          [[202, 203],\n",
       "           [214, 215],\n",
       "           [226, 227],\n",
       "           [238, 239]]],\n",
       "\n",
       "\n",
       "         [[[248, 249],\n",
       "           [260, 261],\n",
       "           [272, 273],\n",
       "           [284, 285]],\n",
       "\n",
       "          [[250, 251],\n",
       "           [262, 263],\n",
       "           [274, 275],\n",
       "           [286, 287]]],\n",
       "\n",
       "\n",
       "         [[[296, 297],\n",
       "           [308, 309],\n",
       "           [320, 321],\n",
       "           [332, 333]],\n",
       "\n",
       "          [[298, 299],\n",
       "           [310, 311],\n",
       "           [322, 323],\n",
       "           [334, 335]]],\n",
       "\n",
       "\n",
       "         [[[344, 345],\n",
       "           [356, 357],\n",
       "           [368, 369],\n",
       "           [380, 381]],\n",
       "\n",
       "          [[346, 347],\n",
       "           [358, 359],\n",
       "           [370, 371],\n",
       "           [382, 383]]]]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead, we need to decompose the embedding dimension into Q,K,V and number of heads\n",
    "# This reshaping splits the embedding dimension into Q,K,V and per head for each patch, a 3 x 2 x 2 tensor\n",
    "# Then we want to keep the final dimension together, as this is the 1st head's 2-vector query\n",
    "# We want to collect these across patches in a window, so we need to go across the within window patch dimension (size 4, position 1)\n",
    "# We want to collect across the head dimension next, so the same within window patches across heads\n",
    "# We collect this together for each window we have\n",
    "# And finally we separate the Q, K and V. \n",
    "t.view(8,4,3,2,2).permute(2,0,3,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb5039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-learning-repo-RWqq603u-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
